{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ac3b448",
   "metadata": {},
   "source": [
    "cannon 3\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8e9509f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('dark_background')\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a4bc1c",
   "metadata": {},
   "source": [
    "Simulation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa8d6caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pi = np.pi\n",
    "\n",
    "#simulates a ballistic trajectory and returns the smallest distance to the target position\n",
    "def simulate_trajectory_distance(speed, azi, pitch, target, origin = np.array([0.,0.,0.]), timestep = 0.1, g = -10.):\n",
    "    #get cartesian velocity from spherical coordinates\n",
    "    velocity = speed*np.array([\n",
    "        np.cos(azi)*np.cos(pitch),\n",
    "        np.sin(azi)*np.cos(pitch),\n",
    "        np.sin(pitch)\n",
    "    ])\n",
    "#     print(f'Starting velocity {velocity}.')\n",
    "    #make acceleration vector\n",
    "    acc = np.array([0.,0., g])\n",
    "    #record origin and first position after 1 timestep\n",
    "    history = [origin, origin+ velocity*timestep + (1/2)*acc*timestep**2]\n",
    "    position = history[-1]\n",
    "#     print(history)\n",
    "    #record distances\n",
    "    distances = [np.linalg.norm(target - origin), np.linalg.norm(target - position)]\n",
    "    #while the ball is above the ground, timestep to change position\n",
    "    while position[2] >= 0:\n",
    "#         print(history[-1])\n",
    "        position = 2*history[-1] - history[-2] + acc*(timestep**2)\n",
    "        distances.append(np.linalg.norm(target - position))\n",
    "        history.append(position)\n",
    "    return np.array(distances).min()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b87cdc47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "221.16372929942816"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance = simulate_trajectory_distance(100, 0, pi/3, np.array([100,200,300]))\n",
    "distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "316c8c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got to optimizing\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No gradients provided for any variable: (['dense_12/kernel:0', 'dense_12/bias:0', 'dense_13/kernel:0', 'dense_13/bias:0'],). Provided `grads_and_vars` is ((None, <tf.Variable 'dense_12/kernel:0' shape=(3, 32) dtype=float32, numpy=\narray([[-0.15404779, -0.38550666,  0.17879567, -0.17078783,  0.10806009,\n        -0.19836852, -0.23261036, -0.23141365,  0.1755592 ,  0.23261878,\n         0.24854323, -0.39840996,  0.02823347,  0.07722616, -0.01893526,\n        -0.24670692, -0.11922294,  0.2161121 , -0.29501492, -0.20330444,\n        -0.24229674, -0.03097439,  0.41262928, -0.382739  , -0.11801398,\n         0.13302818,  0.19009063, -0.25516063,  0.29355344, -0.08093429,\n         0.1984612 , -0.10413104],\n       [-0.37951094,  0.1212146 , -0.2365709 ,  0.3531926 , -0.03570837,\n        -0.27961355, -0.29321268,  0.03928804,  0.07237238,  0.31452605,\n        -0.02526978, -0.25421143, -0.16888985,  0.19756696, -0.13244075,\n        -0.16993947,  0.27660987, -0.15632346, -0.22930066,  0.00114805,\n        -0.1097264 , -0.05406189, -0.19355124, -0.01258031,  0.29900053,\n         0.06782329,  0.1317828 ,  0.04197517, -0.02784801, -0.37060547,\n        -0.40225914, -0.37219882],\n       [-0.25564831, -0.17656116, -0.17717369,  0.04280436,  0.13990417,\n         0.04962495,  0.12629023, -0.3992727 , -0.3041325 ,  0.05853683,\n         0.26148996, -0.06845438,  0.12679121, -0.26507545, -0.40516648,\n         0.33432677,  0.08344579, -0.21144229, -0.3506884 ,  0.0192911 ,\n         0.08101386,  0.01170391,  0.36254802, -0.3512729 , -0.25967684,\n         0.35587624,  0.3424351 , -0.376309  , -0.3731922 , -0.12483951,\n        -0.35300642,  0.00757012]], dtype=float32)>), (None, <tf.Variable 'dense_12/bias:0' shape=(32,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n      dtype=float32)>), (None, <tf.Variable 'dense_13/kernel:0' shape=(32, 3) dtype=float32, numpy=\narray([[ 0.2377747 ,  0.06882268,  0.387374  ],\n       [ 0.21425721,  0.17830238,  0.35538903],\n       [-0.26285803,  0.07655302, -0.40407658],\n       [ 0.3669248 , -0.39127812,  0.06397343],\n       [-0.37730318,  0.1101425 ,  0.31125268],\n       [ 0.11660984,  0.07654643, -0.06719518],\n       [ 0.3461034 , -0.01871353,  0.17144164],\n       [-0.04115838,  0.35045436, -0.21380472],\n       [-0.26269305,  0.29300085, -0.32261682],\n       [ 0.3749464 , -0.3679705 , -0.00288385],\n       [-0.04712433, -0.1821559 , -0.17440543],\n       [-0.07817441, -0.28131133,  0.2021496 ],\n       [ 0.21857038,  0.23637709, -0.15965667],\n       [-0.4038438 , -0.31536525, -0.3739668 ],\n       [-0.40525284,  0.08393046,  0.22487536],\n       [ 0.30602375,  0.04196429, -0.1993222 ],\n       [ 0.21929535,  0.30159137, -0.08979768],\n       [ 0.26951417,  0.29661873,  0.40079758],\n       [ 0.11747679, -0.02387425,  0.10531422],\n       [ 0.10068443,  0.15969923, -0.01148406],\n       [ 0.33112827,  0.15520188,  0.15013883],\n       [ 0.38781872, -0.00183481,  0.39933118],\n       [-0.22809772,  0.12821385,  0.3944203 ],\n       [ 0.24631593, -0.3758723 ,  0.18676797],\n       [-0.15594894, -0.07714057, -0.13252968],\n       [ 0.20709369,  0.18852863,  0.10351971],\n       [ 0.17085138,  0.27892086, -0.3320188 ],\n       [ 0.18210271,  0.00255731,  0.09128955],\n       [ 0.2808145 ,  0.26245084,  0.06991744],\n       [ 0.14541987, -0.29612812,  0.14283922],\n       [-0.17421333, -0.34766972, -0.24903312],\n       [-0.25620672,  0.00083819, -0.27402532]], dtype=float32)>), (None, <tf.Variable 'dense_13/bias:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>)).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8432/1838355342.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'got to optimizing'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mall_scores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[1;34m(self, grads_and_vars, name, experimental_aggregate_gradients)\u001b[0m\n\u001b[0;32m    631\u001b[0m       \u001b[0mRuntimeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mcalled\u001b[0m \u001b[1;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mcross\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mreplica\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    632\u001b[0m     \"\"\"\n\u001b[1;32m--> 633\u001b[1;33m     \u001b[0mgrads_and_vars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter_empty_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    634\u001b[0m     \u001b[0mvar_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mv\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    635\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\utils.py\u001b[0m in \u001b[0;36mfilter_empty_gradients\u001b[1;34m(grads_and_vars)\u001b[0m\n\u001b[0;32m     71\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfiltered\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[0mvariable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m     raise ValueError(f\"No gradients provided for any variable: {variable}. \"\n\u001b[0m\u001b[0;32m     74\u001b[0m                      f\"Provided `grads_and_vars` is {grads_and_vars}.\")\n\u001b[0;32m     75\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mvars_with_empty_grads\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: No gradients provided for any variable: (['dense_12/kernel:0', 'dense_12/bias:0', 'dense_13/kernel:0', 'dense_13/bias:0'],). Provided `grads_and_vars` is ((None, <tf.Variable 'dense_12/kernel:0' shape=(3, 32) dtype=float32, numpy=\narray([[-0.15404779, -0.38550666,  0.17879567, -0.17078783,  0.10806009,\n        -0.19836852, -0.23261036, -0.23141365,  0.1755592 ,  0.23261878,\n         0.24854323, -0.39840996,  0.02823347,  0.07722616, -0.01893526,\n        -0.24670692, -0.11922294,  0.2161121 , -0.29501492, -0.20330444,\n        -0.24229674, -0.03097439,  0.41262928, -0.382739  , -0.11801398,\n         0.13302818,  0.19009063, -0.25516063,  0.29355344, -0.08093429,\n         0.1984612 , -0.10413104],\n       [-0.37951094,  0.1212146 , -0.2365709 ,  0.3531926 , -0.03570837,\n        -0.27961355, -0.29321268,  0.03928804,  0.07237238,  0.31452605,\n        -0.02526978, -0.25421143, -0.16888985,  0.19756696, -0.13244075,\n        -0.16993947,  0.27660987, -0.15632346, -0.22930066,  0.00114805,\n        -0.1097264 , -0.05406189, -0.19355124, -0.01258031,  0.29900053,\n         0.06782329,  0.1317828 ,  0.04197517, -0.02784801, -0.37060547,\n        -0.40225914, -0.37219882],\n       [-0.25564831, -0.17656116, -0.17717369,  0.04280436,  0.13990417,\n         0.04962495,  0.12629023, -0.3992727 , -0.3041325 ,  0.05853683,\n         0.26148996, -0.06845438,  0.12679121, -0.26507545, -0.40516648,\n         0.33432677,  0.08344579, -0.21144229, -0.3506884 ,  0.0192911 ,\n         0.08101386,  0.01170391,  0.36254802, -0.3512729 , -0.25967684,\n         0.35587624,  0.3424351 , -0.376309  , -0.3731922 , -0.12483951,\n        -0.35300642,  0.00757012]], dtype=float32)>), (None, <tf.Variable 'dense_12/bias:0' shape=(32,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n      dtype=float32)>), (None, <tf.Variable 'dense_13/kernel:0' shape=(32, 3) dtype=float32, numpy=\narray([[ 0.2377747 ,  0.06882268,  0.387374  ],\n       [ 0.21425721,  0.17830238,  0.35538903],\n       [-0.26285803,  0.07655302, -0.40407658],\n       [ 0.3669248 , -0.39127812,  0.06397343],\n       [-0.37730318,  0.1101425 ,  0.31125268],\n       [ 0.11660984,  0.07654643, -0.06719518],\n       [ 0.3461034 , -0.01871353,  0.17144164],\n       [-0.04115838,  0.35045436, -0.21380472],\n       [-0.26269305,  0.29300085, -0.32261682],\n       [ 0.3749464 , -0.3679705 , -0.00288385],\n       [-0.04712433, -0.1821559 , -0.17440543],\n       [-0.07817441, -0.28131133,  0.2021496 ],\n       [ 0.21857038,  0.23637709, -0.15965667],\n       [-0.4038438 , -0.31536525, -0.3739668 ],\n       [-0.40525284,  0.08393046,  0.22487536],\n       [ 0.30602375,  0.04196429, -0.1993222 ],\n       [ 0.21929535,  0.30159137, -0.08979768],\n       [ 0.26951417,  0.29661873,  0.40079758],\n       [ 0.11747679, -0.02387425,  0.10531422],\n       [ 0.10068443,  0.15969923, -0.01148406],\n       [ 0.33112827,  0.15520188,  0.15013883],\n       [ 0.38781872, -0.00183481,  0.39933118],\n       [-0.22809772,  0.12821385,  0.3944203 ],\n       [ 0.24631593, -0.3758723 ,  0.18676797],\n       [-0.15594894, -0.07714057, -0.13252968],\n       [ 0.20709369,  0.18852863,  0.10351971],\n       [ 0.17085138,  0.27892086, -0.3320188 ],\n       [ 0.18210271,  0.00255731,  0.09128955],\n       [ 0.2808145 ,  0.26245084,  0.06991744],\n       [ 0.14541987, -0.29612812,  0.14283922],\n       [-0.17421333, -0.34766972, -0.24903312],\n       [-0.25620672,  0.00083819, -0.27402532]], dtype=float32)>), (None, <tf.Variable 'dense_13/bias:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>))."
     ]
    }
   ],
   "source": [
    "seed = 2022\n",
    "rng = np.random.default_rng(seed)\n",
    "\n",
    "#eps == 1.1920928955078125e-07\n",
    "eps = np.finfo(np.float32).eps.item()\n",
    "\n",
    "gamma = 0.99\n",
    "rounds_per_load = 5\n",
    "minimum_acceptible_score = 500\n",
    "scores_to_average = 10\n",
    "max_speed = 100 #m/s\n",
    "field_size = 2000 #m\n",
    "\n",
    "hit_distance = 5 #5m radius of target\n",
    "#miss_penalty = 500 #add this distance as a penalty for missing\n",
    "num_inputs = 3 #target x, y, z\n",
    "num_outputs = 3 #speed/max_speed, azimuth/(2pi), pitch/(pi)(\n",
    "num_hidden = 32\n",
    "\n",
    "#make model\n",
    "inputs = keras.layers.Input(shape = (num_inputs,))\n",
    "dense_1 = keras.layers.Dense(num_hidden, activation = 'relu')(inputs)\n",
    "outputs = keras.layers.Dense(num_outputs)(dense_1)\n",
    "model = keras.Model(inputs = inputs, outputs = outputs)\n",
    "\n",
    "#optimizer and loss function\n",
    "optimizer = tf.optimizers.Adam(learning_rate = 0.01)\n",
    "loss_fn = keras.losses.Huber()\n",
    "\n",
    "avg_recent_score = 0\n",
    "all_scores = [0]\n",
    "total_loss = tf.constant(0.)\n",
    "\n",
    "# model.trainable_variables[1] = tf.convert_to\n",
    "\n",
    "while avg_recent_score < minimum_acceptible_score:\n",
    "    with tf.GradientTape() as tape:\n",
    "        command_history = []\n",
    "        loss_history = []\n",
    "        #reload the cannon and shoot all shots\n",
    "        for shot in range(rounds_per_load):\n",
    "            target = field_size*rng.random(3) - field_size/2\n",
    "            target[2] = abs(target[2])\n",
    "            target = tf.convert_to_tensor(target)\n",
    "            target = tf.expand_dims(target, 0)\n",
    "            \n",
    "            command = model(target)\n",
    "            speed, azi, pitch = command[0]\n",
    "            speed = np.float32(speed*max_speed)\n",
    "            azi = np.float32(azi*2*pi)\n",
    "            pitch = np.float32(pitch*pi)\n",
    "            \n",
    "            loss = simulate_trajectory_distance(speed, azi, pitch, target, timestep = 0.5)\n",
    "            loss = loss_fn([0], [loss])\n",
    "            loss_history.append(loss)\n",
    "            \n",
    "        total_loss = sum(loss_history)\n",
    "        grads = tape.gradient(total_loss, model.trainable_variables)\n",
    "        \n",
    "        print('got to optimizing')\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "        \n",
    "        all_scores.append(total_loss)\n",
    "        loss_history.clear()\n",
    "        avg_recent_score = np.mean(all_scores[-scores_to_average:])\n",
    "        if len(all_scores[:-2])%100 == 0:\n",
    "            print(f'finished with trial {len(all_scores[:-2])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f40d7e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.losses.Huber at 0x2d528e76d30>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5111c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
